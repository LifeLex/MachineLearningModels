import numpy as np  # linear algebra
import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)
import os
from glob import glob
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
This is used to force Keras to use CPUos.environ["CUDA_VISIBLE_DEVICES"]="-1"

all_xray_df = pd.read_csv(r'D:\DescargasChrome\Data_Entry_2017.csv')
all_image_paths = {os.path.basename(x): x for x in
                   glob(os.path.join(r'D:\DescargasChrome', 'input', 'images*', '*', '*.png'))}
print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])
all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)
# all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))
print(all_xray_df.sample(3))

label_counts = all_xray_df['Finding Labels'].value_counts()[:15]
fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))
ax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)
ax1.set_xticks(np.arange(len(label_counts)) + 0.5)
_ = ax1.set_xticklabels(label_counts.index, rotation=90)
plt.show()


all_xray_df['Finding Labels'] = all_xray_df['Finding Labels'].map(lambda x: x.replace('No Finding', ''))
from itertools import chain

all_labels = np.unique(list(chain(*all_xray_df['Finding Labels'].map(lambda x: x.split('|')).tolist())))
all_labels = [x for x in all_labels if len(x) > 0]
print('All Labels ({}): {}'.format(len(all_labels), all_labels))
for c_label in all_labels:
    if len(c_label) > 1:  # leave out empty labels
        all_xray_df[c_label] = all_xray_df['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)
print(all_xray_df.sample(3))

'''
Clean categories
Since we have too many categories, we can prune a few out by taking the ones with only a few examples
'''
# keep at least 1000 cases
MIN_CASES = 1000
all_labels = [c_label for c_label in all_labels if all_xray_df[c_label].sum() > MIN_CASES]
print('Clean Labels ({})'.format(len(all_labels)),
      [(c_label, int(all_xray_df[c_label].sum())) for c_label in all_labels])

# since the dataset is very unbiased, we can resample it to be a more reasonable collection
# weight is 0.1 + number of findings
sample_weights = all_xray_df['Finding Labels'].map(lambda x: len(x.split('|')) if len(x) > 0 else 0).values + 4e-2
sample_weights /= sample_weights.sum()
all_xray_df = all_xray_df.sample(40000, weights=sample_weights)

label_counts = all_xray_df['Finding Labels'].value_counts()[:15]
fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))
ax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)
ax1.set_xticks(np.arange(len(label_counts)) + 0.5)
_ = ax1.set_xticklabels(label_counts.index, rotation=90)
plt.show()

label_counts = 100 * np.mean(all_xray_df[all_labels].values, 0)
fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))
ax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)
ax1.set_xticks(np.arange(len(label_counts)) + 0.5)
ax1.set_xticklabels(all_labels, rotation=90)
ax1.set_title('Adjusted Frequency of Diseases in Patient Group')
_ = ax1.set_ylabel('Frequency (%)')
plt.show()

all_xray_df['disease_vec'] = all_xray_df.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])

from keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = (128, 128)
core_idg = ImageDataGenerator(samplewise_center=True,
                              samplewise_std_normalization=True,
                              horizontal_flip=True,
                              vertical_flip=False,
                              height_shift_range=0.05,
                              width_shift_range=0.1,
                              rotation_range=5,
                              shear_range=0.1,
                              fill_mode='reflect',
                              zoom_range=0.15)


def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):
    base_dir = os.path.dirname(in_df[path_col].values[0])
    print('## Ignore next message from keras, values are replaced anyways')
    df_gen = img_data_gen.flow_from_directory(base_dir,
                                              class_mode='sparse',
                                              **dflow_args)
    df_gen.filenames = in_df[path_col].values
    df_gen.classes = np.stack(in_df[y_col].values)
    df_gen.samples = in_df.shape[0]
    df_gen.n = in_df.shape[0]
    df_gen._set_index_array()
    df_gen.directory = ''  # since we have the full path
    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))
    return df_gen


train_df, valid_df = train_test_split(all_xray_df,
                                      test_size=0.25,
                                      random_state=2018,
                                      stratify=all_xray_df['Finding Labels'].map(lambda x: x[:4]))
print('train', train_df.shape[0], 'validation', valid_df.shape[0])

valid_df['newLabel'] = valid_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)
train_df['newLabel'] = train_df.apply(lambda x: x['Finding Labels'].split('|'), axis=1)

train_gen = core_idg.flow_from_dataframe(dataframe=train_df, directory=None, x_col='path',
                                         y_col='newLabel', class_mode='categorical',
                                         classes=all_labels, target_size=IMG_SIZE, color_mode='grayscale',
                                         batch_size=32)

valid_gen = core_idg.flow_from_dataframe(dataframe=valid_df, directory=None, x_col='path',
                                         y_col='newLabel', class_mode='categorical',
                                         classes=all_labels, target_size=IMG_SIZE, color_mode='grayscale',
                                         batch_size=256)  # we can use much larger batches for evaluation

test_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=valid_df,
                                                   directory=None,
                                                   x_col='path', y_col='newLabel',
                                                   class_mode='categorical', classes=all_labels,
                                                   target_size=IMG_SIZE,
                                                   color_mode='grayscale', batch_size=1024))

# train_gen = flow_from_dataframe(core_idg, train_df,
#                                 path_col='path',
#                                 y_col='disease_vec',
#                                 target_size=IMG_SIZE,
#                                 color_mode='grayscale',
#                                 batch_size=32)
#
# valid_gen = flow_from_dataframe(core_idg, valid_df,
#                                 path_col='path',
#                                 y_col='disease_vec',
#                                 target_size=IMG_SIZE,
#                                 color_mode='grayscale',
#                                 batch_size=256)  # we can use much larger batches for evaluation
# # used a fixed dataset for evaluating the algorithm
# test_X, test_Y = next(flow_from_dataframe(core_idg,
#                                           valid_df,
#                                           path_col='path',
#                                           y_col='disease_vec',
#                                           target_size=IMG_SIZE,
#                                           color_mode='grayscale',
#                                           batch_size=1024))  # one big batch

t_x, t_y = next(train_gen)
fig, m_axs = plt.subplots(4, 4, figsize=(16, 16))
for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):
    c_ax.imshow(c_x[:, :, 0], cmap='bone', vmin=-1.5, vmax=1.5)
    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y)
                              if n_score > 0.5]))
    c_ax.axis('off')
plt.show()


from keras.applications.mobilenet import MobileNet
from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten
from keras.models import Sequential
from keras.applications import  densenet, Xception, NASNetMobile

xception_model= Xception(input_shape=t_x.shape[1:],
                               weights=None,
                               include_top=False)
multi_disease_model = Sequential()
multi_disease_model.add(xception_model)
multi_disease_model.add(GlobalAveragePooling2D())
multi_disease_model.add(Dropout(0.5))
multi_disease_model.add(Dense(512))
multi_disease_model.add(Dropout(0.5))
multi_disease_model.add(Dense(len(all_labels), activation='sigmoid'))
multi_disease_model.compile(optimizer='adam', loss='binary_crossentropy',
                            metrics=['binary_accuracy', 'mae'])
multi_disease_model.summary()

from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau

weight_path = "{}_weights.best.hdf5".format('xray_class')

checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1,
                             save_best_only=True, mode='min', save_weights_only=False)

early = EarlyStopping(monitor="val_loss",
                      mode="min",
                      patience=3)
callbacks_list = [checkpoint, early]

multi_disease_model.fit_generator(train_gen,
                                  steps_per_epoch=100,
                                  validation_data=(test_X, test_Y),
                                  epochs=10,
                                  callbacks=callbacks_list)
multi_disease_model.save('modelo_NIH_Sigmoid21062020.h5')

for c_label, s_count in zip(all_labels, 100 * np.mean(test_Y, 0)):
    print('%s: %2.2f%%' % (c_label, s_count))

pred_Y = multi_disease_model.predict(test_X, batch_size=32, verbose=True)

from sklearn.metrics import roc_curve, auc

fig, c_ax = plt.subplots(1, 1, figsize=(9, 9))
for (idx, c_label) in enumerate(all_labels):
    fpr, tpr, thresholds = roc_curve(test_Y[:, idx].astype(int), pred_Y[:, idx])
    c_ax.plot(fpr, tpr, label='%s (AUC:%0.2f)' % (c_label, auc(fpr, tpr)))
c_ax.legend()
c_ax.set_xlabel('False Positive Rate')
c_ax.set_ylabel('True Positive Rate')
plt.show()
fig.savefig('barely_trained_net_Xception.png')

multi_disease_model.fit_generator(train_gen,
                                  steps_per_epoch=100,
                                  validation_data=(test_X, test_Y),
                                  epochs=15,
                                  callbacks=callbacks_list)

# load the best weights
multi_disease_model.load_weights(weight_path)

pred_Y = multi_disease_model.predict(test_X, batch_size=32, verbose=True)

# look at how often the algorithm predicts certain diagnoses
for c_label, p_count, t_count in zip(all_labels,
                                     100 * np.mean(pred_Y, 0),
                                     100 * np.mean(test_Y, 0)):
    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))

from sklearn.metrics import roc_curve, auc

fig, c_ax = plt.subplots(1, 1, figsize=(9, 9))
for (idx, c_label) in enumerate(all_labels):
    fpr, tpr, thresholds = roc_curve(test_Y[:, idx].astype(int), pred_Y[:, idx])
    c_ax.plot(fpr, tpr, label='%s (AUC:%0.2f)' % (c_label, auc(fpr, tpr)))
c_ax.legend()
c_ax.set_xlabel('False Positive Rate')
c_ax.set_ylabel('True Positive Rate')
plt.show()
fig.savefig('trained_net_Xception.png')


sickest_idx = np.argsort(np.sum(test_Y, 1) < 1)
fig, m_axs = plt.subplots(4, 2, figsize=(16, 32))
for (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):
    c_ax.imshow(test_X[idx, :, :, 0], cmap='bone')
    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels,
                                                        test_Y[idx])
                if n_score > 0.5]
    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score * 100) for n_class, n_score, p_score in zip(all_labels,
                                                                                                 test_Y[idx],
                                                                                                 pred_Y[idx])
                if (n_score > 0.5) or (p_score > 0.5)]
    c_ax.set_title('Dx: ' + ', '.join(stat_str) + '\nPDx: ' + ', '.join(pred_str))
    c_ax.axis('off')
plt.show()
fig.savefig('trained_img_predictions_Xception.png')

